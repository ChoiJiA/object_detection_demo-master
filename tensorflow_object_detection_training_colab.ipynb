{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-object-detection-training-colab.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChoiJiA/object_detection_demo-master/blob/master/tensorflow_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKJErtF8rZCx",
        "colab_type": "text"
      },
      "source": [
        "< 참고 url > \n",
        "1. https://medium.com/datadriveninvestor/how-to-train-your-own-custom-model-with-tensorflow-object-detection-api-and-deploy-it-into-android-aeacab7fa76f\n",
        "2. https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/ChoiJiA/object_detection_demo-master'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 10000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 20\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "80c9d98c-a45d-4298-96db-6f86867ebfd5"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'object_detection_demo-master'...\n",
            "remote: Enumerating objects: 3951, done.\u001b[K\n",
            "remote: Total 3951 (delta 0), reused 0 (delta 0), pack-reused 3951\u001b[K\n",
            "Receiving objects: 100% (3951/3951), 350.71 MiB | 18.44 MiB/s, done.\n",
            "Resolving deltas: 100% (1304/1304), done.\n",
            "Checking out files: 100% (3922/3922), done.\n",
            "/content/object_detection_demo-master\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt2IXmia4AyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "796c83bb-79ab-415f-faeb-e04906858492"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuW7yWzITIQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "fb828474-3d04-4f04-e263-0cacdaf1b156"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.30.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (49.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=0f3c1b7b0e9bb932d3435c51142a906e002bcbb5280ffac7eacd934d091af9e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUXAbOjie8nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e7fa52e-3881-43d6-b5b4-648769adfb6d"
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oeox6MUqYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "159572f1-2aed-4b48-97c7-6339705b89b0"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r                                                                               \rHit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 80.8 kB/88.7 kB 91%] [Connected to cloud.\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r                                                                               \rGet:6 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "\r0% [4 InRelease 15.6 kB/88.7 kB 18%] [1 InRelease 80.8 kB/88.7 kB 91%] [Waiting\r                                                                               \r0% [4 InRelease 15.6 kB/88.7 kB 18%] [Waiting for headers]\r0% [2 InRelease gpgv 21.3 kB] [4 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\r                                                                               \r0% [2 InRelease gpgv 21.3 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [2 InRelease gpgv 21.3 kB] [7 InRelease 8,394 B/74.6 kB 11%] [Waiting for he\r                                                                               \r0% [2 InRelease gpgv 21.3 kB] [Waiting for headers]\r                                                   \rIgn:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 21.3 kB] [Waiting for headers]\r                                                   \r0% [Waiting for headers]\r0% [3 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rIgn:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                  \r0% [3 InRelease gpgv 242 kB]\r                            \rHit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,853 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [894 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [116 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,413 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,334 kB]\n",
            "Fetched 5,909 kB in 2s (3,305 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "135e455b-daf5-412c-83ff-1da84279d738"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezGDABRXXhPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "683254a6-b2bd-4e4d-ac13-d377ea856ec7"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/object_detection_demo-master\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "Successfully created the TFRecords: /content/object_detection_demo-master/data/annotations/train.record\n",
            "Successfully created the TFRecords: /content/object_detection_demo-master/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/object_detection_demo-master/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo-master/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo-master/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3925700-15e9-469b-83f0-09b2c1ce808e"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "1fad4f5f-7b63-4a75-e2d1-594db44af9fe"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Aug  2 02:45 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61c0423f-86ca-4c04-a701-98bd4cdf397a"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7f55727-ef81-46db-f4c2-c3abcc869b15"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 1\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo-master/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo-master/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo-master/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo-master/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "6829fda7-20c1-4788-94fd-558c012bf674"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 02:45:47--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.2.129.46, 54.80.22.251, 52.6.123.150, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.2.129.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  11.8MB/s    in 1.1s    \n",
            "\n",
            "2020-08-02 02:45:48 (11.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47bda3b7-3bfb-48f6-ff85-7abe0d0a0e54"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://6284bff787b7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7fdTq-TG5VF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86dc4468-1cde-4623-abb1-69127b76bc6a"
      },
      "source": [
        "num_eval_steps"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bc46fe-08a4-48e3-b790-4d0e62ccb6e7"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0802 02:45:57.439105 140047141721984 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0802 02:45:57.439341 140047141721984 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0802 02:45:57.439435 140047141721984 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0802 02:45:57.439505 140047141721984 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0802 02:45:57.439576 140047141721984 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0802 02:45:57.439668 140047141721984 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0802 02:45:57.439752 140047141721984 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ecb00f908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0802 02:45:57.440138 140047141721984 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5ecb00f908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5ecb00b840>) includes params argument, but params are not passed to Estimator.\n",
            "W0802 02:45:57.440947 140047141721984 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5ecb00b840>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0802 02:45:57.441731 140047141721984 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0802 02:45:57.441915 140047141721984 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0802 02:45:57.442130 140047141721984 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0802 02:45:57.446842 140047141721984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0802 02:45:57.475452 140047141721984 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0802 02:45:57.480078 140047141721984 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0802 02:45:57.498480 140047141721984 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0802 02:46:07.797032 140047141721984 deprecation.py:323] From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 02:46:07.892886 140047141721984 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0802 02:46:13.843503 140047141721984 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0802 02:46:17.102813 140047141721984 deprecation.py:323] From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 02:46:20.224002 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 02:46:20.392771 140047141721984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.847399 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.874792 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.901014 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.927232 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.953501 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:46:22.980358 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0802 02:46:26.690595 140047141721984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 02:46:32.307050 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0802 02:46:32.308380 140047141721984 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 02:46:35.249269 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 02:46:35.249676: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-08-02 02:46:35.254128: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2020-08-02 02:46:35.254338: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x164b2540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 02:46:35.254370: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 02:46:35.257721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 02:46:35.462164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:35.462816: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x164b2380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 02:46:35.462844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-02 02:46:35.464043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:35.464579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 02:46:35.484791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 02:46:35.729031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 02:46:35.828858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 02:46:35.861005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 02:46:36.131149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 02:46:36.267055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 02:46:36.828407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 02:46:36.828644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:36.829488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:36.830024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 02:46:36.830165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 02:46:36.831625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 02:46:36.831664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 02:46:36.831682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 02:46:36.831820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:36.832436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:46:36.833014: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 02:46:36.833063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 02:46:40.963624 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 02:46:41.254863 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0802 02:46:48.907822 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-08-02 02:46:58.010816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 02:47:03.204614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:loss = 15.958631, step = 0\n",
            "I0802 02:47:06.405511 140047141721984 basic_session_run_hooks.py:262] loss = 15.958631, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.09848\n",
            "I0802 02:47:38.678565 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.09848\n",
            "INFO:tensorflow:loss = 9.158915, step = 100 (32.274 sec)\n",
            "I0802 02:47:38.679542 140047141721984 basic_session_run_hooks.py:260] loss = 9.158915, step = 100 (32.274 sec)\n",
            "2020-08-02 02:47:54.324251: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 40421376 exceeds 10% of system memory.\n",
            "2020-08-02 02:47:56.707767: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 161685504 exceeds 10% of system memory.\n",
            "2020-08-02 02:47:56.842625: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18494784 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global_step/sec: 3.39406\n",
            "I0802 02:48:08.141812 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.39406\n",
            "INFO:tensorflow:loss = 9.138034, step = 200 (29.463 sec)\n",
            "I0802 02:48:08.142855 140047141721984 basic_session_run_hooks.py:260] loss = 9.138034, step = 200 (29.463 sec)\n",
            "2020-08-02 02:48:09.143261: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 40421376 exceeds 10% of system memory.\n",
            "2020-08-02 02:48:10.184537: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 40421376 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global_step/sec: 3.2991\n",
            "I0802 02:48:38.453091 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.2991\n",
            "INFO:tensorflow:loss = 9.157906, step = 300 (30.311 sec)\n",
            "I0802 02:48:38.454142 140047141721984 basic_session_run_hooks.py:260] loss = 9.157906, step = 300 (30.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.24019\n",
            "I0802 02:49:09.315485 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.24019\n",
            "INFO:tensorflow:loss = 9.626738, step = 400 (30.862 sec)\n",
            "I0802 02:49:09.316470 140047141721984 basic_session_run_hooks.py:260] loss = 9.626738, step = 400 (30.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.29041\n",
            "I0802 02:49:39.706815 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.29041\n",
            "INFO:tensorflow:loss = 7.8351727, step = 500 (30.392 sec)\n",
            "I0802 02:49:39.707974 140047141721984 basic_session_run_hooks.py:260] loss = 7.8351727, step = 500 (30.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.39264\n",
            "I0802 02:50:09.182403 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.39264\n",
            "INFO:tensorflow:loss = 7.905139, step = 600 (29.476 sec)\n",
            "I0802 02:50:09.183478 140047141721984 basic_session_run_hooks.py:260] loss = 7.905139, step = 600 (29.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.27301\n",
            "I0802 02:50:39.735324 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.27301\n",
            "INFO:tensorflow:loss = 8.188305, step = 700 (30.553 sec)\n",
            "I0802 02:50:39.736498 140047141721984 basic_session_run_hooks.py:260] loss = 8.188305, step = 700 (30.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21659\n",
            "I0802 02:51:10.824186 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21659\n",
            "INFO:tensorflow:loss = 8.47417, step = 800 (31.089 sec)\n",
            "I0802 02:51:10.825195 140047141721984 basic_session_run_hooks.py:260] loss = 8.47417, step = 800 (31.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.16095\n",
            "I0802 02:51:42.460237 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.16095\n",
            "INFO:tensorflow:loss = 8.190551, step = 900 (31.636 sec)\n",
            "I0802 02:51:42.461469 140047141721984 basic_session_run_hooks.py:260] loss = 8.190551, step = 900 (31.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20057\n",
            "I0802 02:52:13.704730 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20057\n",
            "INFO:tensorflow:loss = 7.5751176, step = 1000 (31.244 sec)\n",
            "I0802 02:52:13.705942 140047141721984 basic_session_run_hooks.py:260] loss = 7.5751176, step = 1000 (31.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.18605\n",
            "I0802 02:52:45.091525 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.18605\n",
            "INFO:tensorflow:loss = 7.400892, step = 1100 (31.387 sec)\n",
            "I0802 02:52:45.093041 140047141721984 basic_session_run_hooks.py:260] loss = 7.400892, step = 1100 (31.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.28202\n",
            "I0802 02:53:15.560552 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.28202\n",
            "INFO:tensorflow:loss = 7.040025, step = 1200 (30.468 sec)\n",
            "I0802 02:53:15.561485 140047141721984 basic_session_run_hooks.py:260] loss = 7.040025, step = 1200 (30.468 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21125\n",
            "I0802 02:53:46.701071 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21125\n",
            "INFO:tensorflow:loss = 8.424341, step = 1300 (31.141 sec)\n",
            "I0802 02:53:46.702313 140047141721984 basic_session_run_hooks.py:260] loss = 8.424341, step = 1300 (31.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25152\n",
            "I0802 02:54:17.455913 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.25152\n",
            "INFO:tensorflow:loss = 8.146304, step = 1400 (30.755 sec)\n",
            "I0802 02:54:17.456862 140047141721984 basic_session_run_hooks.py:260] loss = 8.146304, step = 1400 (30.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.36059\n",
            "I0802 02:54:47.212596 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.36059\n",
            "INFO:tensorflow:loss = 7.0688214, step = 1500 (29.757 sec)\n",
            "I0802 02:54:47.213626 140047141721984 basic_session_run_hooks.py:260] loss = 7.0688214, step = 1500 (29.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.24616\n",
            "I0802 02:55:18.018624 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.24616\n",
            "INFO:tensorflow:loss = 8.538157, step = 1600 (30.806 sec)\n",
            "I0802 02:55:18.019774 140047141721984 basic_session_run_hooks.py:260] loss = 8.538157, step = 1600 (30.806 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22315\n",
            "I0802 02:55:49.043823 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.22315\n",
            "INFO:tensorflow:loss = 8.841986, step = 1700 (31.025 sec)\n",
            "I0802 02:55:49.045040 140047141721984 basic_session_run_hooks.py:260] loss = 8.841986, step = 1700 (31.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23978\n",
            "I0802 02:56:19.910078 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.23978\n",
            "INFO:tensorflow:loss = 8.387475, step = 1800 (30.866 sec)\n",
            "I0802 02:56:19.910932 140047141721984 basic_session_run_hooks.py:260] loss = 8.387475, step = 1800 (30.866 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1901 into training/model.ckpt.\n",
            "I0802 02:56:51.097152 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 1901 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 02:56:53.256414 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.265555 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.294122 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.321887 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.349837 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.376683 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 02:56:55.403857 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0802 02:56:56.019083 140047141721984 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0802 02:56:56.231342 140047141721984 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 02:56:56.727178 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T02:56:56Z\n",
            "I0802 02:56:56.742303 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T02:56:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 02:56:57.125734 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 02:56:57.126838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:56:57.127314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 02:56:57.127435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 02:56:57.127468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 02:56:57.127492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 02:56:57.127516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 02:56:57.127540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 02:56:57.127561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 02:56:57.127583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 02:56:57.127666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:56:57.128123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:56:57.128531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 02:56:57.128610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 02:56:57.128625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 02:56:57.128634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 02:56:57.128728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:56:57.129205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 02:56:57.129661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1901\n",
            "I0802 02:56:57.130810 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-1901\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 02:56:57.976304 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 02:56:58.103952 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 02:57:18.893260 140043484104448 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 02:57:18.896080 140043484104448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 02:57:18.918003 140043484104448 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.23s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-02:57:22\n",
            "I0802 02:57:22.472145 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-02:57:22\n",
            "INFO:tensorflow:Saving dict for global step 1901: DetectionBoxes_Precision/mAP = 0.00070940756, DetectionBoxes_Precision/mAP (large) = 0.0013529245, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0020281663, DetectionBoxes_Precision/mAP@.75IOU = 0.00048129124, DetectionBoxes_Recall/AR@1 = 0.003125, DetectionBoxes_Recall/AR@10 = 0.019642858, DetectionBoxes_Recall/AR@100 = 0.06979167, DetectionBoxes_Recall/AR@100 (large) = 0.15427631, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 6.2259927, Loss/localization_loss = 3.8564787, Loss/regularization_loss = 0.307963, Loss/total_loss = 10.390434, global_step = 1901, learning_rate = 0.004, loss = 10.390434\n",
            "I0802 02:57:22.472503 140047141721984 estimator.py:2049] Saving dict for global step 1901: DetectionBoxes_Precision/mAP = 0.00070940756, DetectionBoxes_Precision/mAP (large) = 0.0013529245, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0020281663, DetectionBoxes_Precision/mAP@.75IOU = 0.00048129124, DetectionBoxes_Recall/AR@1 = 0.003125, DetectionBoxes_Recall/AR@10 = 0.019642858, DetectionBoxes_Recall/AR@100 = 0.06979167, DetectionBoxes_Recall/AR@100 (large) = 0.15427631, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 6.2259927, Loss/localization_loss = 3.8564787, Loss/regularization_loss = 0.307963, Loss/total_loss = 10.390434, global_step = 1901, learning_rate = 0.004, loss = 10.390434\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1901: training/model.ckpt-1901\n",
            "I0802 02:57:23.179519 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1901: training/model.ckpt-1901\n",
            "INFO:tensorflow:global_step/sec: 1.5805\n",
            "I0802 02:57:23.181097 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 1.5805\n",
            "INFO:tensorflow:loss = 7.1992526, step = 1900 (63.271 sec)\n",
            "I0802 02:57:23.182188 140047141721984 basic_session_run_hooks.py:260] loss = 7.1992526, step = 1900 (63.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.26443\n",
            "I0802 02:57:53.814426 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.26443\n",
            "INFO:tensorflow:loss = 7.3584337, step = 2000 (30.633 sec)\n",
            "I0802 02:57:53.815555 140047141721984 basic_session_run_hooks.py:260] loss = 7.3584337, step = 2000 (30.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20364\n",
            "I0802 02:58:25.028905 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20364\n",
            "INFO:tensorflow:loss = 7.114397, step = 2100 (31.214 sec)\n",
            "I0802 02:58:25.029945 140047141721984 basic_session_run_hooks.py:260] loss = 7.114397, step = 2100 (31.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.17494\n",
            "I0802 02:58:56.525595 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.17494\n",
            "INFO:tensorflow:loss = 7.88112, step = 2200 (31.497 sec)\n",
            "I0802 02:58:56.527122 140047141721984 basic_session_run_hooks.py:260] loss = 7.88112, step = 2200 (31.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15925\n",
            "I0802 02:59:28.178692 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.15925\n",
            "INFO:tensorflow:loss = 8.069216, step = 2300 (31.653 sec)\n",
            "I0802 02:59:28.179701 140047141721984 basic_session_run_hooks.py:260] loss = 8.069216, step = 2300 (31.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.11968\n",
            "I0802 03:00:00.233262 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.11968\n",
            "INFO:tensorflow:loss = 7.472678, step = 2400 (32.055 sec)\n",
            "I0802 03:00:00.234508 140047141721984 basic_session_run_hooks.py:260] loss = 7.472678, step = 2400 (32.055 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.09801\n",
            "I0802 03:00:32.512004 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.09801\n",
            "INFO:tensorflow:loss = 6.712947, step = 2500 (32.278 sec)\n",
            "I0802 03:00:32.512939 140047141721984 basic_session_run_hooks.py:260] loss = 6.712947, step = 2500 (32.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14345\n",
            "I0802 03:01:04.324192 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.14345\n",
            "INFO:tensorflow:loss = 7.6787014, step = 2600 (31.812 sec)\n",
            "I0802 03:01:04.325253 140047141721984 basic_session_run_hooks.py:260] loss = 7.6787014, step = 2600 (31.812 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15873\n",
            "I0802 03:01:35.982512 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.15873\n",
            "INFO:tensorflow:loss = 6.713541, step = 2700 (31.658 sec)\n",
            "I0802 03:01:35.983454 140047141721984 basic_session_run_hooks.py:260] loss = 6.713541, step = 2700 (31.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.16293\n",
            "I0802 03:02:07.598814 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.16293\n",
            "INFO:tensorflow:loss = 7.2388906, step = 2800 (31.616 sec)\n",
            "I0802 03:02:07.599762 140047141721984 basic_session_run_hooks.py:260] loss = 7.2388906, step = 2800 (31.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19403\n",
            "I0802 03:02:38.907192 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19403\n",
            "INFO:tensorflow:loss = 6.940639, step = 2900 (31.309 sec)\n",
            "I0802 03:02:38.908776 140047141721984 basic_session_run_hooks.py:260] loss = 6.940639, step = 2900 (31.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.18327\n",
            "I0802 03:03:10.321475 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.18327\n",
            "INFO:tensorflow:loss = 6.6990232, step = 3000 (31.414 sec)\n",
            "I0802 03:03:10.322527 140047141721984 basic_session_run_hooks.py:260] loss = 6.6990232, step = 3000 (31.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1823\n",
            "I0802 03:03:41.745304 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.1823\n",
            "INFO:tensorflow:loss = 7.331392, step = 3100 (31.424 sec)\n",
            "I0802 03:03:41.746464 140047141721984 basic_session_run_hooks.py:260] loss = 7.331392, step = 3100 (31.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25148\n",
            "I0802 03:04:12.500510 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.25148\n",
            "INFO:tensorflow:loss = 7.04299, step = 3200 (30.755 sec)\n",
            "I0802 03:04:12.501714 140047141721984 basic_session_run_hooks.py:260] loss = 7.04299, step = 3200 (30.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.24671\n",
            "I0802 03:04:43.300865 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.24671\n",
            "INFO:tensorflow:loss = 7.0343757, step = 3300 (30.800 sec)\n",
            "I0802 03:04:43.302043 140047141721984 basic_session_run_hooks.py:260] loss = 7.0343757, step = 3300 (30.800 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.17427\n",
            "I0802 03:05:14.804184 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.17427\n",
            "INFO:tensorflow:loss = 6.996698, step = 3400 (31.503 sec)\n",
            "I0802 03:05:14.805747 140047141721984 basic_session_run_hooks.py:260] loss = 6.996698, step = 3400 (31.503 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22683\n",
            "I0802 03:05:45.794368 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.22683\n",
            "INFO:tensorflow:loss = 8.47682, step = 3500 (30.990 sec)\n",
            "I0802 03:05:45.795523 140047141721984 basic_session_run_hooks.py:260] loss = 8.47682, step = 3500 (30.990 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.29371\n",
            "I0802 03:06:16.155241 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.29371\n",
            "INFO:tensorflow:loss = 6.6707773, step = 3600 (30.361 sec)\n",
            "I0802 03:06:16.156638 140047141721984 basic_session_run_hooks.py:260] loss = 6.6707773, step = 3600 (30.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.243\n",
            "I0802 03:06:46.990918 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.243\n",
            "INFO:tensorflow:loss = 7.5788436, step = 3700 (30.835 sec)\n",
            "I0802 03:06:46.992067 140047141721984 basic_session_run_hooks.py:260] loss = 7.5788436, step = 3700 (30.835 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3715 into training/model.ckpt.\n",
            "I0802 03:06:51.301630 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 3715 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:06:53.209855 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.175185 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.202891 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.230225 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.257484 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.284476 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:06:55.311758 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:06:56.605876 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T03:06:56Z\n",
            "I0802 03:06:56.622074 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T03:06:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 03:06:57.037010 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 03:06:57.037767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:06:57.038251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:06:57.038395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:06:57.038429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:06:57.038455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:06:57.038479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:06:57.038501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:06:57.038524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:06:57.038547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:06:57.038630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:06:57.039079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:06:57.039523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:06:57.039603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:06:57.039617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:06:57.039627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:06:57.039734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:06:57.040187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:06:57.040613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3715\n",
            "I0802 03:06:57.041576 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-3715\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 03:06:57.899764 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 03:06:58.013444 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 03:07:17.434471 140043484104448 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 03:07:17.435786 140043484104448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 03:07:17.454985 140043484104448 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-03:07:21\n",
            "I0802 03:07:21.014861 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-03:07:21\n",
            "INFO:tensorflow:Saving dict for global step 3715: DetectionBoxes_Precision/mAP = 0.0009712009, DetectionBoxes_Precision/mAP (large) = 0.0017111687, DetectionBoxes_Precision/mAP (medium) = 4.8274866e-05, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.002807776, DetectionBoxes_Precision/mAP@.75IOU = 0.00061127875, DetectionBoxes_Recall/AR@1 = 0.004761905, DetectionBoxes_Recall/AR@10 = 0.020684524, DetectionBoxes_Recall/AR@100 = 0.06636905, DetectionBoxes_Recall/AR@100 (large) = 0.14276315, DetectionBoxes_Recall/AR@100 (medium) = 0.003908795, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.901803, Loss/localization_loss = 4.1974277, Loss/regularization_loss = 0.3075383, Loss/total_loss = 10.40677, global_step = 3715, learning_rate = 0.004, loss = 10.40677\n",
            "I0802 03:07:21.015152 140047141721984 estimator.py:2049] Saving dict for global step 3715: DetectionBoxes_Precision/mAP = 0.0009712009, DetectionBoxes_Precision/mAP (large) = 0.0017111687, DetectionBoxes_Precision/mAP (medium) = 4.8274866e-05, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.002807776, DetectionBoxes_Precision/mAP@.75IOU = 0.00061127875, DetectionBoxes_Recall/AR@1 = 0.004761905, DetectionBoxes_Recall/AR@10 = 0.020684524, DetectionBoxes_Recall/AR@100 = 0.06636905, DetectionBoxes_Recall/AR@100 (large) = 0.14276315, DetectionBoxes_Recall/AR@100 (medium) = 0.003908795, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.901803, Loss/localization_loss = 4.1974277, Loss/regularization_loss = 0.3075383, Loss/total_loss = 10.40677, global_step = 3715, learning_rate = 0.004, loss = 10.40677\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3715: training/model.ckpt-3715\n",
            "I0802 03:07:21.018829 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3715: training/model.ckpt-3715\n",
            "INFO:tensorflow:global_step/sec: 1.66865\n",
            "I0802 03:07:46.919560 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 1.66865\n",
            "INFO:tensorflow:loss = 6.7487235, step = 3800 (59.928 sec)\n",
            "I0802 03:07:46.920519 140047141721984 basic_session_run_hooks.py:260] loss = 6.7487235, step = 3800 (59.928 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.31281\n",
            "I0802 03:08:17.105404 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.31281\n",
            "INFO:tensorflow:loss = 6.378882, step = 3900 (30.186 sec)\n",
            "I0802 03:08:17.106440 140047141721984 basic_session_run_hooks.py:260] loss = 6.378882, step = 3900 (30.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.26165\n",
            "I0802 03:08:47.764725 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.26165\n",
            "INFO:tensorflow:loss = 7.0761986, step = 4000 (30.659 sec)\n",
            "I0802 03:08:47.765702 140047141721984 basic_session_run_hooks.py:260] loss = 7.0761986, step = 4000 (30.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20314\n",
            "I0802 03:09:18.984118 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20314\n",
            "INFO:tensorflow:loss = 6.836373, step = 4100 (31.220 sec)\n",
            "I0802 03:09:18.985320 140047141721984 basic_session_run_hooks.py:260] loss = 6.836373, step = 4100 (31.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21548\n",
            "I0802 03:09:50.083744 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21548\n",
            "INFO:tensorflow:loss = 7.0469804, step = 4200 (31.100 sec)\n",
            "I0802 03:09:50.084856 140047141721984 basic_session_run_hooks.py:260] loss = 7.0469804, step = 4200 (31.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21339\n",
            "I0802 03:10:21.203491 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21339\n",
            "INFO:tensorflow:loss = 6.6490684, step = 4300 (31.120 sec)\n",
            "I0802 03:10:21.204579 140047141721984 basic_session_run_hooks.py:260] loss = 6.6490684, step = 4300 (31.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19656\n",
            "I0802 03:10:52.487169 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19656\n",
            "INFO:tensorflow:loss = 6.5534577, step = 4400 (31.284 sec)\n",
            "I0802 03:10:52.488131 140047141721984 basic_session_run_hooks.py:260] loss = 6.5534577, step = 4400 (31.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20857\n",
            "I0802 03:11:23.653763 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20857\n",
            "INFO:tensorflow:loss = 6.629716, step = 4500 (31.167 sec)\n",
            "I0802 03:11:23.655215 140047141721984 basic_session_run_hooks.py:260] loss = 6.629716, step = 4500 (31.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20242\n",
            "I0802 03:11:54.880130 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20242\n",
            "INFO:tensorflow:loss = 7.2341394, step = 4600 (31.226 sec)\n",
            "I0802 03:11:54.881083 140047141721984 basic_session_run_hooks.py:260] loss = 7.2341394, step = 4600 (31.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21644\n",
            "I0802 03:12:25.970364 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21644\n",
            "INFO:tensorflow:loss = 7.290353, step = 4700 (31.090 sec)\n",
            "I0802 03:12:25.971320 140047141721984 basic_session_run_hooks.py:260] loss = 7.290353, step = 4700 (31.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22023\n",
            "I0802 03:12:57.024029 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.22023\n",
            "INFO:tensorflow:loss = 7.3201685, step = 4800 (31.054 sec)\n",
            "I0802 03:12:57.025147 140047141721984 basic_session_run_hooks.py:260] loss = 7.3201685, step = 4800 (31.054 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20336\n",
            "I0802 03:13:28.241199 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20336\n",
            "INFO:tensorflow:loss = 7.59981, step = 4900 (31.217 sec)\n",
            "I0802 03:13:28.242190 140047141721984 basic_session_run_hooks.py:260] loss = 7.59981, step = 4900 (31.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.17465\n",
            "I0802 03:13:59.740763 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.17465\n",
            "INFO:tensorflow:loss = 7.752176, step = 5000 (31.500 sec)\n",
            "I0802 03:13:59.741981 140047141721984 basic_session_run_hooks.py:260] loss = 7.752176, step = 5000 (31.500 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.16563\n",
            "I0802 03:14:31.330032 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.16563\n",
            "INFO:tensorflow:loss = 6.6183023, step = 5100 (31.589 sec)\n",
            "I0802 03:14:31.331271 140047141721984 basic_session_run_hooks.py:260] loss = 6.6183023, step = 5100 (31.589 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21631\n",
            "I0802 03:15:02.421571 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21631\n",
            "INFO:tensorflow:loss = 6.7079105, step = 5200 (31.092 sec)\n",
            "I0802 03:15:02.423112 140047141721984 basic_session_run_hooks.py:260] loss = 6.7079105, step = 5200 (31.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22807\n",
            "I0802 03:15:33.399798 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.22807\n",
            "INFO:tensorflow:loss = 6.544272, step = 5300 (30.978 sec)\n",
            "I0802 03:15:33.400946 140047141721984 basic_session_run_hooks.py:260] loss = 6.544272, step = 5300 (30.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19854\n",
            "I0802 03:16:04.664086 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19854\n",
            "INFO:tensorflow:loss = 6.623898, step = 5400 (31.264 sec)\n",
            "I0802 03:16:04.665391 140047141721984 basic_session_run_hooks.py:260] loss = 6.623898, step = 5400 (31.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19255\n",
            "I0802 03:16:35.986968 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19255\n",
            "INFO:tensorflow:loss = 7.1242366, step = 5500 (31.323 sec)\n",
            "I0802 03:16:35.988023 140047141721984 basic_session_run_hooks.py:260] loss = 7.1242366, step = 5500 (31.323 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5551 into training/model.ckpt.\n",
            "I0802 03:16:51.509171 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 5551 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:16:53.432813 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.411735 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.439614 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.466583 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.494362 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.521033 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:16:55.548250 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:16:56.864704 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T03:16:56Z\n",
            "I0802 03:16:56.881483 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T03:16:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 03:16:57.314977 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 03:16:57.315666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:16:57.316177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:16:57.316279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:16:57.316335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:16:57.316364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:16:57.316390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:16:57.316415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:16:57.316439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:16:57.316464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:16:57.316564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:16:57.317061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:16:57.317492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:16:57.317538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:16:57.317554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:16:57.317570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:16:57.317672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:16:57.318139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:16:57.318575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5551\n",
            "I0802 03:16:57.319658 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-5551\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 03:16:58.217840 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 03:16:58.340049 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 03:17:17.766915 140043484104448 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 03:17:17.769054 140043484104448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 03:17:17.789748 140043484104448 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.23s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-03:17:21\n",
            "I0802 03:17:21.241704 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-03:17:21\n",
            "INFO:tensorflow:Saving dict for global step 5551: DetectionBoxes_Precision/mAP = 0.00064893067, DetectionBoxes_Precision/mAP (large) = 0.0013577264, DetectionBoxes_Precision/mAP (medium) = 0.0001980198, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0019962224, DetectionBoxes_Precision/mAP@.75IOU = 0.00037696987, DetectionBoxes_Recall/AR@1 = 0.002232143, DetectionBoxes_Recall/AR@10 = 0.03154762, DetectionBoxes_Recall/AR@100 = 0.069196425, DetectionBoxes_Recall/AR@100 (large) = 0.15230264, DetectionBoxes_Recall/AR@100 (medium) = 0.0006514658, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.6498365, Loss/localization_loss = 3.883139, Loss/regularization_loss = 0.3069312, Loss/total_loss = 9.839906, global_step = 5551, learning_rate = 0.004, loss = 9.839906\n",
            "I0802 03:17:21.241955 140047141721984 estimator.py:2049] Saving dict for global step 5551: DetectionBoxes_Precision/mAP = 0.00064893067, DetectionBoxes_Precision/mAP (large) = 0.0013577264, DetectionBoxes_Precision/mAP (medium) = 0.0001980198, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0019962224, DetectionBoxes_Precision/mAP@.75IOU = 0.00037696987, DetectionBoxes_Recall/AR@1 = 0.002232143, DetectionBoxes_Recall/AR@10 = 0.03154762, DetectionBoxes_Recall/AR@100 = 0.069196425, DetectionBoxes_Recall/AR@100 (large) = 0.15230264, DetectionBoxes_Recall/AR@100 (medium) = 0.0006514658, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.6498365, Loss/localization_loss = 3.883139, Loss/regularization_loss = 0.3069312, Loss/total_loss = 9.839906, global_step = 5551, learning_rate = 0.004, loss = 9.839906\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5551: training/model.ckpt-5551\n",
            "I0802 03:17:21.245464 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5551: training/model.ckpt-5551\n",
            "INFO:tensorflow:global_step/sec: 1.63953\n",
            "I0802 03:17:36.980117 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 1.63953\n",
            "INFO:tensorflow:loss = 7.0504413, step = 5600 (60.994 sec)\n",
            "I0802 03:17:36.981606 140047141721984 basic_session_run_hooks.py:260] loss = 7.0504413, step = 5600 (60.994 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19702\n",
            "I0802 03:18:08.259235 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19702\n",
            "INFO:tensorflow:loss = 6.090502, step = 5700 (31.279 sec)\n",
            "I0802 03:18:08.260410 140047141721984 basic_session_run_hooks.py:260] loss = 6.090502, step = 5700 (31.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20592\n",
            "I0802 03:18:39.451499 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20592\n",
            "INFO:tensorflow:loss = 6.436573, step = 5800 (31.192 sec)\n",
            "I0802 03:18:39.452632 140047141721984 basic_session_run_hooks.py:260] loss = 6.436573, step = 5800 (31.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.18887\n",
            "I0802 03:19:10.810527 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.18887\n",
            "INFO:tensorflow:loss = 7.360454, step = 5900 (31.359 sec)\n",
            "I0802 03:19:10.811552 140047141721984 basic_session_run_hooks.py:260] loss = 7.360454, step = 5900 (31.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.18293\n",
            "I0802 03:19:42.228135 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.18293\n",
            "INFO:tensorflow:loss = 6.5501633, step = 6000 (31.418 sec)\n",
            "I0802 03:19:42.229305 140047141721984 basic_session_run_hooks.py:260] loss = 6.5501633, step = 6000 (31.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21597\n",
            "I0802 03:20:13.322958 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21597\n",
            "INFO:tensorflow:loss = 6.2257338, step = 6100 (31.095 sec)\n",
            "I0802 03:20:13.324351 140047141721984 basic_session_run_hooks.py:260] loss = 6.2257338, step = 6100 (31.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20218\n",
            "I0802 03:20:44.551627 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20218\n",
            "INFO:tensorflow:loss = 6.3275123, step = 6200 (31.228 sec)\n",
            "I0802 03:20:44.552710 140047141721984 basic_session_run_hooks.py:260] loss = 6.3275123, step = 6200 (31.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20087\n",
            "I0802 03:21:15.793172 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20087\n",
            "INFO:tensorflow:loss = 7.325141, step = 6300 (31.242 sec)\n",
            "I0802 03:21:15.794267 140047141721984 basic_session_run_hooks.py:260] loss = 7.325141, step = 6300 (31.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1675\n",
            "I0802 03:21:47.363790 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.1675\n",
            "INFO:tensorflow:loss = 8.119988, step = 6400 (31.570 sec)\n",
            "I0802 03:21:47.364731 140047141721984 basic_session_run_hooks.py:260] loss = 8.119988, step = 6400 (31.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22438\n",
            "I0802 03:22:18.377485 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.22438\n",
            "INFO:tensorflow:loss = 6.983331, step = 6500 (31.014 sec)\n",
            "I0802 03:22:18.378960 140047141721984 basic_session_run_hooks.py:260] loss = 6.983331, step = 6500 (31.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20066\n",
            "I0802 03:22:49.620998 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.20066\n",
            "INFO:tensorflow:loss = 6.2653265, step = 6600 (31.243 sec)\n",
            "I0802 03:22:49.622204 140047141721984 basic_session_run_hooks.py:260] loss = 6.2653265, step = 6600 (31.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21288\n",
            "I0802 03:23:20.745792 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.21288\n",
            "INFO:tensorflow:loss = 7.0684, step = 6700 (31.126 sec)\n",
            "I0802 03:23:20.747973 140047141721984 basic_session_run_hooks.py:260] loss = 7.0684, step = 6700 (31.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23014\n",
            "I0802 03:23:51.704193 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.23014\n",
            "INFO:tensorflow:loss = 7.7318406, step = 6800 (30.957 sec)\n",
            "I0802 03:23:51.705162 140047141721984 basic_session_run_hooks.py:260] loss = 7.7318406, step = 6800 (30.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19924\n",
            "I0802 03:24:22.961611 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19924\n",
            "INFO:tensorflow:loss = 6.688316, step = 6900 (31.258 sec)\n",
            "I0802 03:24:22.962940 140047141721984 basic_session_run_hooks.py:260] loss = 6.688316, step = 6900 (31.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2565\n",
            "I0802 03:24:53.669434 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.2565\n",
            "INFO:tensorflow:loss = 6.877482, step = 7000 (30.708 sec)\n",
            "I0802 03:24:53.670625 140047141721984 basic_session_run_hooks.py:260] loss = 6.877482, step = 7000 (30.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.24313\n",
            "I0802 03:25:24.503978 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.24313\n",
            "INFO:tensorflow:loss = 7.2479525, step = 7100 (30.835 sec)\n",
            "I0802 03:25:24.505267 140047141721984 basic_session_run_hooks.py:260] loss = 7.2479525, step = 7100 (30.835 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.17114\n",
            "I0802 03:25:56.038308 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.17114\n",
            "INFO:tensorflow:loss = 7.0418377, step = 7200 (31.534 sec)\n",
            "I0802 03:25:56.039425 140047141721984 basic_session_run_hooks.py:260] loss = 7.0418377, step = 7200 (31.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.11244\n",
            "I0802 03:26:28.167457 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.11244\n",
            "INFO:tensorflow:loss = 6.8601036, step = 7300 (32.129 sec)\n",
            "I0802 03:26:28.168713 140047141721984 basic_session_run_hooks.py:260] loss = 6.8601036, step = 7300 (32.129 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7376 into training/model.ckpt.\n",
            "I0802 03:26:51.641044 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 7376 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:26:54.045422 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:55.962938 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:55.992737 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:56.021904 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:56.052108 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:56.080585 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:26:56.108844 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:26:57.419646 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T03:26:57Z\n",
            "I0802 03:26:57.439885 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T03:26:57Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 03:26:57.827485 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 03:26:57.828336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:26:57.828855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:26:57.828967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:26:57.828996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:26:57.829019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:26:57.829042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:26:57.829064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:26:57.829083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:26:57.829104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:26:57.829191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:26:57.829715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:26:57.830113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:26:57.830344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:26:57.830361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:26:57.830371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:26:57.830494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:26:57.830953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:26:57.831362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7376\n",
            "I0802 03:26:57.832397 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-7376\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 03:26:58.783965 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 03:26:58.926745 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 03:27:19.210397 140043484104448 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 03:27:19.211884 140043484104448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 03:27:19.233049 140043484104448 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.23s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-03:27:22\n",
            "I0802 03:27:22.769167 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-03:27:22\n",
            "INFO:tensorflow:Saving dict for global step 7376: DetectionBoxes_Precision/mAP = 0.0009757292, DetectionBoxes_Precision/mAP (large) = 0.0019754805, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.003558163, DetectionBoxes_Precision/mAP@.75IOU = 0.0005079359, DetectionBoxes_Recall/AR@1 = 0.005654762, DetectionBoxes_Recall/AR@10 = 0.031845238, DetectionBoxes_Recall/AR@100 = 0.08422619, DetectionBoxes_Recall/AR@100 (large) = 0.18618421, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.4230056, Loss/localization_loss = 3.7845979, Loss/regularization_loss = 0.30636546, Loss/total_loss = 9.513968, global_step = 7376, learning_rate = 0.004, loss = 9.513968\n",
            "I0802 03:27:22.769464 140047141721984 estimator.py:2049] Saving dict for global step 7376: DetectionBoxes_Precision/mAP = 0.0009757292, DetectionBoxes_Precision/mAP (large) = 0.0019754805, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.003558163, DetectionBoxes_Precision/mAP@.75IOU = 0.0005079359, DetectionBoxes_Recall/AR@1 = 0.005654762, DetectionBoxes_Recall/AR@10 = 0.031845238, DetectionBoxes_Recall/AR@100 = 0.08422619, DetectionBoxes_Recall/AR@100 (large) = 0.18618421, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.4230056, Loss/localization_loss = 3.7845979, Loss/regularization_loss = 0.30636546, Loss/total_loss = 9.513968, global_step = 7376, learning_rate = 0.004, loss = 9.513968\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7376: training/model.ckpt-7376\n",
            "I0802 03:27:22.773098 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7376: training/model.ckpt-7376\n",
            "INFO:tensorflow:global_step/sec: 1.60515\n",
            "I0802 03:27:30.466743 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 1.60515\n",
            "INFO:tensorflow:loss = 7.0368705, step = 7400 (62.299 sec)\n",
            "I0802 03:27:30.467813 140047141721984 basic_session_run_hooks.py:260] loss = 7.0368705, step = 7400 (62.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.19624\n",
            "I0802 03:28:01.753597 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.19624\n",
            "INFO:tensorflow:loss = 7.510708, step = 7500 (31.287 sec)\n",
            "I0802 03:28:01.754668 140047141721984 basic_session_run_hooks.py:260] loss = 7.510708, step = 7500 (31.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34074\n",
            "I0802 03:28:31.687021 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34074\n",
            "INFO:tensorflow:loss = 6.4879723, step = 7600 (29.934 sec)\n",
            "I0802 03:28:31.688466 140047141721984 basic_session_run_hooks.py:260] loss = 6.4879723, step = 7600 (29.934 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.27254\n",
            "I0802 03:29:02.244392 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.27254\n",
            "INFO:tensorflow:loss = 7.1671185, step = 7700 (30.557 sec)\n",
            "I0802 03:29:02.245802 140047141721984 basic_session_run_hooks.py:260] loss = 7.1671185, step = 7700 (30.557 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34106\n",
            "I0802 03:29:32.174937 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34106\n",
            "INFO:tensorflow:loss = 6.8475924, step = 7800 (29.930 sec)\n",
            "I0802 03:29:32.176270 140047141721984 basic_session_run_hooks.py:260] loss = 6.8475924, step = 7800 (29.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34502\n",
            "I0802 03:30:02.070147 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34502\n",
            "INFO:tensorflow:loss = 8.508124, step = 7900 (29.895 sec)\n",
            "I0802 03:30:02.071369 140047141721984 basic_session_run_hooks.py:260] loss = 8.508124, step = 7900 (29.895 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.31831\n",
            "I0802 03:30:32.205954 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.31831\n",
            "INFO:tensorflow:loss = 6.2959776, step = 8000 (30.136 sec)\n",
            "I0802 03:30:32.206993 140047141721984 basic_session_run_hooks.py:260] loss = 6.2959776, step = 8000 (30.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.28178\n",
            "I0802 03:31:02.677213 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.28178\n",
            "INFO:tensorflow:loss = 6.382071, step = 8100 (30.471 sec)\n",
            "I0802 03:31:02.678248 140047141721984 basic_session_run_hooks.py:260] loss = 6.382071, step = 8100 (30.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.35105\n",
            "I0802 03:31:32.518639 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.35105\n",
            "INFO:tensorflow:loss = 6.9288516, step = 8200 (29.841 sec)\n",
            "I0802 03:31:32.519630 140047141721984 basic_session_run_hooks.py:260] loss = 6.9288516, step = 8200 (29.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.28671\n",
            "I0802 03:32:02.944231 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.28671\n",
            "INFO:tensorflow:loss = 7.1707826, step = 8300 (30.426 sec)\n",
            "I0802 03:32:02.945334 140047141721984 basic_session_run_hooks.py:260] loss = 7.1707826, step = 8300 (30.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34716\n",
            "I0802 03:32:32.820332 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34716\n",
            "INFO:tensorflow:loss = 6.4800963, step = 8400 (29.876 sec)\n",
            "I0802 03:32:32.821601 140047141721984 basic_session_run_hooks.py:260] loss = 6.4800963, step = 8400 (29.876 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34163\n",
            "I0802 03:33:02.745802 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34163\n",
            "INFO:tensorflow:loss = 7.366247, step = 8500 (29.925 sec)\n",
            "I0802 03:33:02.746751 140047141721984 basic_session_run_hooks.py:260] loss = 7.366247, step = 8500 (29.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.3937\n",
            "I0802 03:33:32.212170 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.3937\n",
            "INFO:tensorflow:loss = 6.196195, step = 8600 (29.467 sec)\n",
            "I0802 03:33:32.213318 140047141721984 basic_session_run_hooks.py:260] loss = 6.196195, step = 8600 (29.467 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.35024\n",
            "I0802 03:34:02.060815 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.35024\n",
            "INFO:tensorflow:loss = 6.5526257, step = 8700 (29.849 sec)\n",
            "I0802 03:34:02.062043 140047141721984 basic_session_run_hooks.py:260] loss = 6.5526257, step = 8700 (29.849 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.38284\n",
            "I0802 03:34:31.621742 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.38284\n",
            "INFO:tensorflow:loss = 6.783993, step = 8800 (29.561 sec)\n",
            "I0802 03:34:31.622918 140047141721984 basic_session_run_hooks.py:260] loss = 6.783993, step = 8800 (29.561 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.43876\n",
            "I0802 03:35:00.701957 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.43876\n",
            "INFO:tensorflow:loss = 6.5523143, step = 8900 (29.080 sec)\n",
            "I0802 03:35:00.703364 140047141721984 basic_session_run_hooks.py:260] loss = 6.5523143, step = 8900 (29.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.36938\n",
            "I0802 03:35:30.381011 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.36938\n",
            "INFO:tensorflow:loss = 6.983057, step = 9000 (29.679 sec)\n",
            "I0802 03:35:30.382227 140047141721984 basic_session_run_hooks.py:260] loss = 6.983057, step = 9000 (29.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.3191\n",
            "I0802 03:36:00.509680 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.3191\n",
            "INFO:tensorflow:loss = 7.0071917, step = 9100 (30.129 sec)\n",
            "I0802 03:36:00.510778 140047141721984 basic_session_run_hooks.py:260] loss = 7.0071917, step = 9100 (30.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.41155\n",
            "I0802 03:36:29.821874 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.41155\n",
            "INFO:tensorflow:loss = 6.346028, step = 9200 (29.312 sec)\n",
            "I0802 03:36:29.823022 140047141721984 basic_session_run_hooks.py:260] loss = 6.346028, step = 9200 (29.312 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9274 into training/model.ckpt.\n",
            "I0802 03:36:51.815160 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 9274 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0802 03:36:51.908675 140047141721984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:36:54.099068 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.112601 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.141084 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.167800 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.195889 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.222758 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:36:56.249669 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:36:57.529127 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T03:36:57Z\n",
            "I0802 03:36:57.544371 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T03:36:57Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 03:36:57.929814 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 03:36:57.930594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:36:57.931145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:36:57.931256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:36:57.931359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:36:57.931427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:36:57.931450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:36:57.931472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:36:57.931495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:36:57.931519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:36:57.931608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:36:57.932077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:36:57.932486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:36:57.932607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:36:57.932622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:36:57.932631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:36:57.932732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:36:57.933181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:36:57.933629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-9274\n",
            "I0802 03:36:57.934904 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-9274\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 03:36:58.852167 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 03:36:58.977142 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 03:37:18.978960 140043492497152 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 03:37:18.980428 140043492497152 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 03:37:19.001834 140043492497152 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.24s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-03:37:22\n",
            "I0802 03:37:22.627900 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-03:37:22\n",
            "INFO:tensorflow:Saving dict for global step 9274: DetectionBoxes_Precision/mAP = 0.0043920237, DetectionBoxes_Precision/mAP (large) = 0.007764855, DetectionBoxes_Precision/mAP (medium) = 0.007585361, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.011772434, DetectionBoxes_Precision/mAP@.75IOU = 0.0018937022, DetectionBoxes_Recall/AR@1 = 0.01607143, DetectionBoxes_Recall/AR@10 = 0.033184525, DetectionBoxes_Recall/AR@100 = 0.11755952, DetectionBoxes_Recall/AR@100 (large) = 0.24078947, DetectionBoxes_Recall/AR@100 (medium) = 0.018892508, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.220424, Loss/localization_loss = 3.2659755, Loss/regularization_loss = 0.30581602, Loss/total_loss = 8.7922125, global_step = 9274, learning_rate = 0.004, loss = 8.7922125\n",
            "I0802 03:37:22.628215 140047141721984 estimator.py:2049] Saving dict for global step 9274: DetectionBoxes_Precision/mAP = 0.0043920237, DetectionBoxes_Precision/mAP (large) = 0.007764855, DetectionBoxes_Precision/mAP (medium) = 0.007585361, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.011772434, DetectionBoxes_Precision/mAP@.75IOU = 0.0018937022, DetectionBoxes_Recall/AR@1 = 0.01607143, DetectionBoxes_Recall/AR@10 = 0.033184525, DetectionBoxes_Recall/AR@100 = 0.11755952, DetectionBoxes_Recall/AR@100 (large) = 0.24078947, DetectionBoxes_Recall/AR@100 (medium) = 0.018892508, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.220424, Loss/localization_loss = 3.2659755, Loss/regularization_loss = 0.30581602, Loss/total_loss = 8.7922125, global_step = 9274, learning_rate = 0.004, loss = 8.7922125\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9274: training/model.ckpt-9274\n",
            "I0802 03:37:22.632139 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9274: training/model.ckpt-9274\n",
            "INFO:tensorflow:global_step/sec: 1.63561\n",
            "I0802 03:37:30.961124 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 1.63561\n",
            "INFO:tensorflow:loss = 6.4133983, step = 9300 (61.139 sec)\n",
            "I0802 03:37:30.962379 140047141721984 basic_session_run_hooks.py:260] loss = 6.4133983, step = 9300 (61.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.34685\n",
            "I0802 03:38:00.839984 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.34685\n",
            "INFO:tensorflow:loss = 6.0302167, step = 9400 (29.879 sec)\n",
            "I0802 03:38:00.841130 140047141721984 basic_session_run_hooks.py:260] loss = 6.0302167, step = 9400 (29.879 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2876\n",
            "I0802 03:38:31.257398 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.2876\n",
            "INFO:tensorflow:loss = 6.6120005, step = 9500 (30.418 sec)\n",
            "I0802 03:38:31.258648 140047141721984 basic_session_run_hooks.py:260] loss = 6.6120005, step = 9500 (30.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.33046\n",
            "I0802 03:39:01.283195 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.33046\n",
            "INFO:tensorflow:loss = 7.3104978, step = 9600 (30.026 sec)\n",
            "I0802 03:39:01.284338 140047141721984 basic_session_run_hooks.py:260] loss = 7.3104978, step = 9600 (30.026 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.32247\n",
            "I0802 03:39:31.381272 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.32247\n",
            "INFO:tensorflow:loss = 7.6581235, step = 9700 (30.098 sec)\n",
            "I0802 03:39:31.382249 140047141721984 basic_session_run_hooks.py:260] loss = 7.6581235, step = 9700 (30.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.26302\n",
            "I0802 03:40:02.027727 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.26302\n",
            "INFO:tensorflow:loss = 6.4628897, step = 9800 (30.647 sec)\n",
            "I0802 03:40:02.028808 140047141721984 basic_session_run_hooks.py:260] loss = 6.4628897, step = 9800 (30.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.24301\n",
            "I0802 03:40:32.863318 140047141721984 basic_session_run_hooks.py:692] global_step/sec: 3.24301\n",
            "INFO:tensorflow:loss = 6.2374635, step = 9900 (30.836 sec)\n",
            "I0802 03:40:32.864404 140047141721984 basic_session_run_hooks.py:260] loss = 6.2374635, step = 9900 (30.836 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n",
            "I0802 03:41:02.726062 140047141721984 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0802 03:41:03.965092 140047141721984 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:41:04.664007 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:06.891803 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:06.919423 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:06.949378 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:06.981657 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:07.008594 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:07.035273 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:41:08.311954 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-02T03:41:08Z\n",
            "I0802 03:41:08.326944 140047141721984 evaluation.py:255] Starting evaluation at 2020-08-02T03:41:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0802 03:41:08.703795 140047141721984 monitored_session.py:240] Graph was finalized.\n",
            "2020-08-02 03:41:08.704445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:08.704921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:08.705028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:08.705059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:08.705085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:08.705107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:08.705128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:08.705151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:08.705174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:08.705261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:08.705742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:08.706144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:08.706190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:41:08.706203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:41:08.706212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:41:08.706321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:08.706771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:08.707182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0802 03:41:08.708432 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0802 03:41:09.599756 140047141721984 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0802 03:41:09.732119 140047141721984 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 300 images.\n",
            "I0802 03:41:29.558655 140043492497152 coco_evaluation.py:237] Performing evaluation on 300 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0802 03:41:29.560321 140043492497152 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0802 03:41:29.581088 140043492497152 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.24s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-02-03:41:33\n",
            "I0802 03:41:33.066747 140047141721984 evaluation.py:275] Finished evaluation at 2020-08-02-03:41:33\n",
            "INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.0022397488, DetectionBoxes_Precision/mAP (large) = 0.0035275808, DetectionBoxes_Precision/mAP (medium) = 0.00018037141, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.005071431, DetectionBoxes_Precision/mAP@.75IOU = 0.0025591298, DetectionBoxes_Recall/AR@1 = 0.003720238, DetectionBoxes_Recall/AR@10 = 0.032589287, DetectionBoxes_Recall/AR@100 = 0.083035715, DetectionBoxes_Recall/AR@100 (large) = 0.15164474, DetectionBoxes_Recall/AR@100 (medium) = 0.03159609, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.0889516, Loss/localization_loss = 3.1145318, Loss/regularization_loss = 0.30559546, Loss/total_loss = 8.50908, global_step = 10000, learning_rate = 0.004, loss = 8.50908\n",
            "I0802 03:41:33.067003 140047141721984 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.0022397488, DetectionBoxes_Precision/mAP (large) = 0.0035275808, DetectionBoxes_Precision/mAP (medium) = 0.00018037141, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.005071431, DetectionBoxes_Precision/mAP@.75IOU = 0.0025591298, DetectionBoxes_Recall/AR@1 = 0.003720238, DetectionBoxes_Recall/AR@10 = 0.032589287, DetectionBoxes_Recall/AR@100 = 0.083035715, DetectionBoxes_Recall/AR@100 (large) = 0.15164474, DetectionBoxes_Recall/AR@100 (medium) = 0.03159609, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.0889516, Loss/localization_loss = 3.1145318, Loss/regularization_loss = 0.30559546, Loss/total_loss = 8.50908, global_step = 10000, learning_rate = 0.004, loss = 8.50908\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "I0802 03:41:33.070573 140047141721984 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0802 03:41:33.071271 140047141721984 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0802 03:41:33.309159 140047141721984 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.486138 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.516053 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.550749 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.579649 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.609071 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:35.638118 140047141721984 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0802 03:41:36.241948 140047141721984 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0802 03:41:36.242233 140047141721984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0802 03:41:36.242854 140047141721984 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0802 03:41:36.242965 140047141721984 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0802 03:41:36.243051 140047141721984 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0802 03:41:36.243121 140047141721984 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0802 03:41:36.243183 140047141721984 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-08-02 03:41:36.243777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:36.244265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:36.244376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:36.244404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:36.244430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:36.244451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:36.244474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:36.244497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:36.244521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:36.244610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:36.245069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:36.245477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:36.245519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:41:36.245533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:41:36.245542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:41:36.245642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:36.246098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:36.246517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0802 03:41:36.248767 140047141721984 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0802 03:41:36.687656 140047141721984 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0802 03:41:36.687903 140047141721984 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1596339693'/saved_model.pb\n",
            "I0802 03:41:37.375636 140047141721984 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1596339693'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 7.141627.\n",
            "I0802 03:41:37.768256 140047141721984 estimator.py:371] Loss for final step: 7.141627.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "74e17a28-3149-4144-fee5-dfa98e04d1de"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1596336393.37b4cba7520f\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-10000.data-00000-of-00001\n",
            "model.ckpt-10000.index\n",
            "model.ckpt-10000.meta\n",
            "model.ckpt-3715.data-00000-of-00001\n",
            "model.ckpt-3715.index\n",
            "model.ckpt-3715.meta\n",
            "model.ckpt-5551.data-00000-of-00001\n",
            "model.ckpt-5551.index\n",
            "model.ckpt-5551.meta\n",
            "model.ckpt-7376.data-00000-of-00001\n",
            "model.ckpt-7376.index\n",
            "model.ckpt-7376.meta\n",
            "model.ckpt-9274.data-00000-of-00001\n",
            "model.ckpt-9274.index\n",
            "model.ckpt-9274.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Nrqw3nqnCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fbb8546-f4a8-46a9-e10b-4cf485b2bec5"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 03:41:49.930969 140011145275264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:51.919998 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:51.955476 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:52.094840 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:52.128815 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:52.162720 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 03:41:52.202187 140011145275264 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 03:41:52.436673 140011145275264 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0802 03:41:52.733877 140011145275264 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0802 03:41:52.736879 140011145275264 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0802 03:41:52.737395 140011145275264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.57m params)\n",
            "  BoxPredictor_0 (--/10.39k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.46k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n",
            "  BoxPredictor_1 (--/46.12k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/15.37k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-08-02 03:41:54.481740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 03:41:54.516971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.517542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:54.517892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:54.519162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:54.520539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:54.520949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:54.530955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:54.532158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:54.538277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:54.538411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.538988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.539486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:54.544025: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-08-02 03:41:54.548732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2020-08-02 03:41:54.548920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2742f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 03:41:54.548946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 03:41:54.653675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.654362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27432c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 03:41:54.654389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-02 03:41:54.654560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.655063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:54.655125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:54.655150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:54.655174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:54.655194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:54.655217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:54.655235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:54.655255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:54.655353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.655919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.656407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:54.656482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:54.657620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:41:54.657646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:41:54.657655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:41:54.657788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.658351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:54.658846: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 03:41:54.658885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0802 03:41:54.660736 140011145275264 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 03:41:56.212637 140011145275264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-08-02 03:41:56.643755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:56.644340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:56.644433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:56.644458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:56.644479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:56.644499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:56.644518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:56.644538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:56.644559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:56.644646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:56.645178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:56.645672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:56.645712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:41:56.645726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:41:56.645734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:41:56.645841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:56.646397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:56.646879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0802 03:41:56.648046 140011145275264 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0802 03:41:57.216442 140011145275264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0802 03:41:57.216722 140011145275264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0802 03:41:57.561032 140011145275264 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0802 03:41:57.634769 140011145275264 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2020-08-02 03:41:57.756935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:57.757583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 03:41:57.757682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 03:41:57.757711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 03:41:57.757738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 03:41:57.757762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 03:41:57.757790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 03:41:57.757815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 03:41:57.757840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 03:41:57.757965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:57.758739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:57.759244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 03:41:57.759298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 03:41:57.759313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 03:41:57.759322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 03:41:57.759415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:57.759941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 03:41:57.760443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0802 03:41:58.248202 140011145275264 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0802 03:41:58.248902 140011145275264 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0802 03:41:58.249050 140011145275264 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0802 03:41:58.461128 140011145275264 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0802 03:41:58.491103 140011145275264 config_util.py:254] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e645f9f2-1306-40ac-a82d-b9b9c90551f1"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b741a2d3-6d54-48cc-e19f-84964e76f0d9"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 19M Aug  2 03:41 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw",
        "colab_type": "text"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c35c5a-b3cd-4446-c6d9-6c7a27c9c7dd"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1biD9FG9Vi3XE6Xy5J-jzICWb-c4YlhyH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs",
        "colab_type": "text"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9167c5ab-752e-44cc-b835-e3db474691e6"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bea081a7-a937-4ae8-9dec-d9de8748d216\", \"frozen_inference_graph.pb\", 19156352)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS",
        "colab_type": "text"
      },
      "source": [
        "### Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5e9c984d-d065-48eb-f375-38d167b74eab"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3b39cddf-dc7c-41d2-a915-de7482537606\", \"label_map.pbtxt\", 41)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq",
        "colab_type": "text"
      },
      "source": [
        "### Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ad318517-29b2-4d06-ba0a-a18e53c484ea"
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_15615546-4385-4003-8d47-3cedd1bc8152\", \"ssd_mobilenet_v2_coco.config\", 4813)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab7a4852-7787-43e4-b78d-ab4b951dc2c9"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/object_detection_demo-master/test/0.jpg', '/content/object_detection_demo-master/test/15.jpg', '/content/object_detection_demo-master/test/10.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa994572-f21b-4bca-a451-3c77dddb1f3c"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RO87aPl0Nf",
        "colab_type": "text"
      },
      "source": [
        "# Convert .pb to .tflite "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIY9mbhoT58y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e55b796-ab90-4cb3-d3b1-3c93b003b126"
      },
      "source": [
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path={pipeline_fname} --trained_checkpoint_prefix=/content/models/research/training/model.ckpt-10000 --output_directory=/content/object_detection_demo-master/ --add_postprocessing_op=true"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 05:03:54.001519 139909803374464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:55.877351 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:55.909115 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:55.935511 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:55.961827 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:55.988454 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 05:03:56.016849 139909803374464 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "2020-08-02 05:03:56.162032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 05:03:56.167028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.167540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 05:03:56.167802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:03:56.169039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 05:03:56.170153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 05:03:56.170519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 05:03:56.172136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 05:03:56.173413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 05:03:56.176913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 05:03:56.177035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.177571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.178006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 05:03:56.178315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-08-02 05:03:56.182878: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2020-08-02 05:03:56.183072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bd8d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 05:03:56.183098: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 05:03:56.271429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.272082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bd8bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 05:03:56.272110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-02 05:03:56.272279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.272852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 05:03:56.272925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:03:56.272951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 05:03:56.272971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 05:03:56.272991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 05:03:56.273011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 05:03:56.273030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 05:03:56.273050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 05:03:56.273117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.273646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.274093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 05:03:56.274157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:03:56.275260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 05:03:56.275300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 05:03:56.275316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 05:03:56.275420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.275903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:56.276372: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 05:03:56.276411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12075 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 05:03:57.168217 139909803374464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-08-02 05:03:57.523784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:57.524409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 05:03:57.524500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:03:57.524529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 05:03:57.524553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 05:03:57.524576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 05:03:57.524604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 05:03:57.524626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 05:03:57.524650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 05:03:57.524739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:57.525622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:57.526164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 05:03:57.526209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 05:03:57.526226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 05:03:57.526237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 05:03:57.526369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:57.526940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:03:57.527472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12075 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/training/model.ckpt-10000\n",
            "I0802 05:03:57.528877 139909803374464 saver.py:1284] Restoring parameters from /content/models/research/training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0802 05:03:58.038918 139909803374464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0802 05:03:58.039183 139909803374464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0802 05:03:58.306231 139909803374464 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0802 05:03:58.356878 139909803374464 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2020-08-02 05:03:58.440263: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58FPNj_UjvGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "d0227326-8f83-4a77-c27e-b9fb01c7ff51"
      },
      "source": [
        "!toco \\\n",
        " --graph_def_file=/content/object_detection_demo-master/tflite_graph.pb \\\n",
        " --output_file=/content/object_detection_demo-master/detect.tflite \\\n",
        " --input_shapes=1,300,300,3 \\\n",
        " --input_arrays=normalized_input_image_tensor \\\n",
        " --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        " --inference_type=FLOAT \\\n",
        " --allow_custom_ops"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-02 05:09:02.813973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-02 05:09:02.818314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.818819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 05:09:02.819048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:09:02.820238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 05:09:02.834972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 05:09:02.835354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 05:09:02.837036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 05:09:02.845211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 05:09:02.849000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 05:09:02.849096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.849639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.850085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 05:09:02.850410: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-08-02 05:09:02.854946: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2020-08-02 05:09:02.855124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1672a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 05:09:02.855150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-02 05:09:02.939790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.940409: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1672bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-02 05:09:02.940440: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-02 05:09:02.940595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.941053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-08-02 05:09:02.941105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:09:02.941125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-08-02 05:09:02.941144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-08-02 05:09:02.941161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-08-02 05:09:02.941179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-08-02 05:09:02.941197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-08-02 05:09:02.941216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-02 05:09:02.941326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.941814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.942255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-08-02 05:09:02.942326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-08-02 05:09:02.943198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-02 05:09:02.943226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-08-02 05:09:02.943236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-08-02 05:09:02.943364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.943862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-02 05:09:02.944331: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-02 05:09:02.944371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12075 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}